#!/usr/bin/env python3
"""
ç®€åŒ–çš„ OpenAI è®¾ç½®æµ‹è¯•è„šæœ¬ - æ—  Pylance å¯¼å…¥é”™è¯¯
"""

import os
import sys
import json

def test_basic_setup():
    """æµ‹è¯•åŸºæœ¬çš„ OpenAI è®¾ç½®"""
    print("=== OpenAI åŸºç¡€è®¾ç½®æ£€æŸ¥ ===\n")
    
    # æ£€æŸ¥ .env æ–‡ä»¶
    env_path = os.path.join(os.path.dirname(__file__), '.env')
    if os.path.exists(env_path):
        print("âœ… .env æ–‡ä»¶å­˜åœ¨")
        
        # å°è¯•åŠ è½½ dotenv
        try:
            from dotenv import load_dotenv
            load_dotenv(env_path)
            print("âœ… python-dotenv å·²å®‰è£…å¹¶åŠ è½½")
        except ImportError:
            print("âš ï¸  python-dotenv æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install python-dotenv")
            return False
    else:
        print("âŒ .env æ–‡ä»¶ä¸å­˜åœ¨")
        return False
    
    # æ£€æŸ¥ API Key
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("âŒ OPENAI_API_KEY æœªè®¾ç½®")
        return False
    elif api_key == "your_openai_api_key_here":
        print("âš ï¸  è¯·æ›¿æ¢é»˜è®¤çš„ API Key å ä½ç¬¦")
        return False
    elif not api_key.startswith('sk-'):
        print("âš ï¸  API Key æ ¼å¼å¯èƒ½ä¸æ­£ç¡®")
        return False
    else:
        print(f"âœ… OPENAI_API_KEY å·²æ­£ç¡®è®¾ç½® ({api_key[:10]}...)")
        return True

def test_openai_library():
    """æµ‹è¯• OpenAI åº“"""
    print("\n=== OpenAI åº“æµ‹è¯• ===\n")
    
    try:
        from openai import OpenAI
        print("âœ… OpenAI åº“å·²å®‰è£…")
        
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            print("âŒ API Key æœªè®¾ç½®ï¼Œè·³è¿‡è¿æ¥æµ‹è¯•")
            return False
            
        client = OpenAI(api_key=api_key)
        print("âœ… OpenAI å®¢æˆ·ç«¯åˆ›å»ºæˆåŠŸ")
        return True
        
    except ImportError:
        print("âŒ OpenAI åº“æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install openai")
        return False
    except Exception as e:
        print(f"âŒ OpenAI å®¢æˆ·ç«¯åˆ›å»ºå¤±è´¥: {e}")
        return False

def test_file_structure():
    """æµ‹è¯•æ–‡ä»¶ç»“æ„"""
    print("\n=== æ–‡ä»¶ç»“æ„æ£€æŸ¥ ===\n")
    
    base_dir = os.path.dirname(__file__)
    required_files = [
        '../automl-llm/app/llm_agent.py',
        '../automl-llm/app/ui_streamlit.py',
        'prompts/task_detection.txt',
        'prompts/research_questions.txt'
    ]
    
    all_exist = True
    for file_path in required_files:
        full_path = os.path.join(base_dir, file_path)
        if os.path.exists(full_path):
            print(f"âœ… {file_path}")
        else:
            print(f"âŒ {file_path} - æ–‡ä»¶ä¸å­˜åœ¨")
            all_exist = False
    
    return all_exist

def test_simple_api_call():
    """æµ‹è¯•ç®€å•çš„ API è°ƒç”¨"""
    print("\n=== API è¿æ¥æµ‹è¯• ===\n")
    
    try:
        from openai import OpenAI
        
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            print("âŒ API Key æœªè®¾ç½®")
            return False
            
        client = OpenAI(api_key=api_key)
        
        print("æ­£åœ¨æµ‹è¯• API è¿æ¥...")
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "user", "content": "è¯·å›å¤'æµ‹è¯•æˆåŠŸ'"}
            ],
            max_tokens=10,
            temperature=0
        )
        
        result = response.choices[0].message.content.strip()
        print(f"âœ… API è¿æ¥æˆåŠŸï¼å“åº”: {result}")
        return True
        
    except Exception as e:
        error_msg = str(e)
        print(f"âŒ API è°ƒç”¨å¤±è´¥: {error_msg}")
        
        # æä¾›å…·ä½“çš„è§£å†³å»ºè®®
        if "authentication" in error_msg.lower():
            print("ğŸ’¡ å»ºè®®: æ£€æŸ¥ API Key æ˜¯å¦æ­£ç¡®")
        elif "quota" in error_msg.lower():
            print("ğŸ’¡ å»ºè®®: æ£€æŸ¥ OpenAI è´¦æˆ·ä½™é¢")
        elif "rate" in error_msg.lower():
            print("ğŸ’¡ å»ºè®®: API è°ƒç”¨é¢‘ç‡è¿‡é«˜ï¼Œè¯·ç¨åå†è¯•")
        else:
            print("ğŸ’¡ å»ºè®®: æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ– OpenAI æœåŠ¡çŠ¶æ€")
            
        return False

def create_sample_profile():
    """åˆ›å»ºç¤ºä¾‹æ•°æ®é…ç½®æ–‡ä»¶ç”¨äºæµ‹è¯•"""
    return {
        "shape": [150, 5],
        "columns": [
            {
                "name": "sepal_length",
                "dtype": "float64",
                "missing_pct": 0.0,
                "unique_count": 35,
                "sample_values": [5.1, 4.9, 4.7]
            },
            {
                "name": "sepal_width", 
                "dtype": "float64",
                "missing_pct": 0.0,
                "unique_count": 23,
                "sample_values": [3.5, 3.0, 3.2]
            },
            {
                "name": "species",
                "dtype": "object", 
                "missing_pct": 0.0,
                "unique_count": 3,
                "sample_values": ["setosa", "versicolor", "virginica"]
            }
        ],
        "dataset_description": "é¸¢å°¾èŠ±æ•°æ®é›† - ç»å…¸åˆ†ç±»æ•°æ®"
    }

def test_research_questions_workflow():
    """æµ‹è¯•ç ”ç©¶é—®é¢˜å‘ç°å·¥ä½œæµ"""
    print("\n=== ç ”ç©¶é—®é¢˜å‘ç°åŠŸèƒ½æµ‹è¯• ===\n")
    
    try:
        from openai import OpenAI
        
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            print("âŒ éœ€è¦ API Key è¿›è¡Œæ­¤æµ‹è¯•")
            return False
            
        # è¯»å– research_questions.txt prompt
        prompt_path = os.path.join(os.path.dirname(__file__), 'prompts', 'research_questions.txt')
        if not os.path.exists(prompt_path):
            print("âŒ research_questions.txt æ–‡ä»¶ä¸å­˜åœ¨")
            return False
            
        with open(prompt_path, 'r', encoding='utf-8') as f:
            system_prompt = f.read()
        
        client = OpenAI(api_key=api_key)
        sample_profile = create_sample_profile()
        
        print("æ­£åœ¨æµ‹è¯•ç ”ç©¶é—®é¢˜å‘ç°åŠŸèƒ½...")
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            temperature=0.3,
            response_format={"type": "json_object"},
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": json.dumps({
                    "dataset_profile": sample_profile
                }, ensure_ascii=False)}
            ],
        )
        
        result = json.loads(response.choices[0].message.content)
        
        print("âœ… ç ”ç©¶é—®é¢˜å‘ç°åŠŸèƒ½æµ‹è¯•æˆåŠŸï¼")
        
        # æ˜¾ç¤ºéƒ¨åˆ†ç»“æœ
        questions = result.get("research_questions", [])
        if questions:
            print(f"\nå‘ç° {len(questions)} ä¸ªç ”ç©¶é—®é¢˜:")
            for i, q in enumerate(questions[:2]):  # åªæ˜¾ç¤ºå‰2ä¸ª
                print(f"  {i+1}. {q.get('question', 'æœªçŸ¥')}")
        
        scenarios = result.get("application_scenarios", [])
        if scenarios:
            print(f"\nåº”ç”¨åœºæ™¯: {scenarios[0] if scenarios else 'æ— '}")
            
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ§ª OpenAI è®¾ç½®å®Œæ•´æ€§æµ‹è¯•\n")
    
    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    tests = [
        ("åŸºç¡€è®¾ç½®", test_basic_setup),
        ("OpenAI åº“", test_openai_library), 
        ("æ–‡ä»¶ç»“æ„", test_file_structure),
        ("API è¿æ¥", test_simple_api_call),
        ("é—®é¢˜å‘ç°åŠŸèƒ½", test_research_questions_workflow)
    ]
    
    results = []
    for test_name, test_func in tests:
        try:
            result = test_func()
            results.append((test_name, result))
        except Exception as e:
            print(f"âŒ {test_name} æµ‹è¯•å‡ºé”™: {e}")
            results.append((test_name, False))
    
    # æ€»ç»“
    print("\n" + "="*60)
    print("ğŸ“Š æµ‹è¯•ç»“æœæ€»ç»“")
    print("="*60)
    
    passed = 0
    for test_name, result in results:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"{test_name:20} {status}")
        if result:
            passed += 1
    
    print(f"\né€šè¿‡ç‡: {passed}/{len(results)} ({passed/len(results)*100:.0f}%)")
    
    if passed == len(results):
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ä½ çš„ AutoML ç³»ç»Ÿå·²å‡†å¤‡å°±ç»ªï¼")
        print("\nğŸš€ ç°åœ¨å¯ä»¥è¿è¡Œ:")
        print("   streamlit run automl-llm/app/ui_streamlit.py")
    else:
        print("\nâš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä¸Šè¿°é”™è¯¯å¹¶ä¿®å¤")

if __name__ == "__main__":
    main()